{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ebfece-c436-4718-9a52-6b489ec519ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching historical data for EUR/USD (1day)...\n",
      "Fetching historical data for GBP/USD (1day)...\n",
      "Fetching historical data for USD/JPY (1day)...\n",
      "Fetching historical data for USD/CHF (1day)...\n",
      "Fetching historical data for AUD/USD (1day)...\n",
      "Fetching historical data for USD/CAD (1day)...\n",
      "Fetching live data for EUR/USD (5min)...\n",
      "Fetching live data for EUR/USD (15min)...\n",
      "Fetching live data for EUR/USD (1h)...\n",
      "Fetching live data for GBP/USD (5min)...\n",
      "Fetching live data for GBP/USD (15min)...\n",
      "Fetching live data for GBP/USD (1h)...\n",
      "Fetching live data for USD/JPY (5min)...\n",
      "Fetching live data for USD/JPY (15min)...\n",
      "Fetching live data for USD/JPY (1h)...\n",
      "Fetching live data for USD/CHF (5min)...\n",
      "Fetching live data for USD/CHF (15min)...\n",
      "Fetching live data for USD/CHF (1h)...\n",
      "Fetching live data for AUD/USD (5min)...\n",
      "Fetching live data for AUD/USD (15min)...\n",
      "Fetching live data for AUD/USD (1h)...\n",
      "Fetching live data for USD/CAD (5min)...\n",
      "Fetching live data for USD/CAD (15min)...\n",
      "Fetching live data for USD/CAD (1h)...\n",
      "✅ Data successfully combined. Columns: Index(['datetime', 'open', 'high', 'low', 'close', 'currency_pair',\n",
      "       'timeframe'],\n",
      "      dtype='object')\n",
      "✅ New model trained and saved as 'new_forex_model_twelvedata.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from twelvedata import TDClient\n",
    "\n",
    "# Step 1: Set up API Key (Replace with your actual API key)\n",
    "API_KEY = \"c4755b2a48af47e498144d182962c441\"  # Updated API key\n",
    "td = TDClient(apikey=API_KEY)\n",
    "\n",
    "# Step 2: Define currency pairs\n",
    "currency_pairs = [\"EUR/USD\", \"GBP/USD\", \"USD/JPY\", \"USD/CHF\", \"AUD/USD\", \"USD/CAD\"]\n",
    "timeframes = [\"1day\"]  # Historical data\n",
    "small_intervals = [\"5min\", \"15min\", \"1h\"]  # Live data\n",
    "\n",
    "# Step 3: Function to fetch forex data\n",
    "def fetch_forex_data(pair, interval=\"1day\", outputsize=5000):\n",
    "    try:\n",
    "        data = td.time_series(\n",
    "            symbol=pair,\n",
    "            interval=interval,\n",
    "            outputsize=outputsize,\n",
    "            timezone=\"UTC\"\n",
    "        ).as_pandas()\n",
    "        data[\"currency_pair\"] = pair\n",
    "        data[\"timeframe\"] = interval\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {pair} ({interval}) data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 4: Fetch historical forex data\n",
    "historical_data = []\n",
    "for pair in currency_pairs:\n",
    "    for tf in timeframes:\n",
    "        print(f\"Fetching historical data for {pair} ({tf})...\")\n",
    "        data = fetch_forex_data(pair, interval=tf, outputsize=5000)\n",
    "        if data is not None:\n",
    "            historical_data.append(data)\n",
    "        time.sleep(10)  # Prevent API rate limits\n",
    "\n",
    "historical_df = pd.concat(historical_data, ignore_index=False) if historical_data else None\n",
    "\n",
    "# Step 5: Fetch live forex data for smaller timeframes\n",
    "live_data = []\n",
    "for pair in currency_pairs:\n",
    "    for tf in small_intervals:\n",
    "        print(f\"Fetching live data for {pair} ({tf})...\")\n",
    "        live = fetch_forex_data(pair, interval=tf, outputsize=5000)\n",
    "        if live is not None:\n",
    "            live_data.append(live)\n",
    "        time.sleep(10)\n",
    "\n",
    "live_df = pd.concat(live_data, ignore_index=False) if live_data else None\n",
    "\n",
    "# Step 6: Merge historical & live data\n",
    "if historical_df is not None and live_df is not None:\n",
    "    combined_df = pd.concat([historical_df, live_df], ignore_index=False)\n",
    "elif historical_df is not None:\n",
    "    combined_df = historical_df\n",
    "elif live_df is not None:\n",
    "    combined_df = live_df\n",
    "else:\n",
    "    raise ValueError(\"No forex data fetched!\")\n",
    "\n",
    "combined_df.reset_index(inplace=True)\n",
    "print(\"✅ Data successfully combined. Columns:\", combined_df.columns)\n",
    "\n",
    "# Step 7: Ensure required columns exist\n",
    "required_cols = [\"close\", \"high\", \"low\"]\n",
    "for col in required_cols:\n",
    "    if col not in combined_df.columns:\n",
    "        raise ValueError(f\"Missing '{col}' column in dataset.\")\n",
    "\n",
    "# Step 8: Calculate ATR for SL & TP\n",
    "def calculate_atr(df, period=14):\n",
    "    df[\"H-L\"] = df[\"high\"] - df[\"low\"]\n",
    "    df[\"H-PC\"] = abs(df[\"high\"] - df[\"close\"].shift(1))\n",
    "    df[\"L-PC\"] = abs(df[\"low\"] - df[\"close\"].shift(1))\n",
    "    df[\"TR\"] = df[[\"H-L\", \"H-PC\", \"L-PC\"]].max(axis=1)\n",
    "    df[\"ATR\"] = df[\"TR\"].rolling(window=period).mean()\n",
    "    df.drop([\"H-L\", \"H-PC\", \"L-PC\", \"TR\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "combined_df = calculate_atr(combined_df)\n",
    "\n",
    "# Step 9: Create SL and TP based on ATR\n",
    "def calculate_sl_tp(df):\n",
    "    df[\"SL\"] = np.where(df[\"close\"].shift(-1) > df[\"close\"],  # If next close is higher (Buy)\n",
    "                        df[\"close\"] - (df[\"ATR\"] * 1.5),      # SL below entry\n",
    "                        df[\"close\"] + (df[\"ATR\"] * 1.5))      # SL above entry\n",
    "\n",
    "    df[\"TP\"] = np.where(df[\"close\"].shift(-1) > df[\"close\"],\n",
    "                        df[\"close\"] + (df[\"ATR\"] * 2),        # TP above entry for Buy\n",
    "                        df[\"close\"] - (df[\"ATR\"] * 2))        # TP below entry for Sell\n",
    "    return df\n",
    "\n",
    "combined_df = calculate_sl_tp(combined_df)\n",
    "\n",
    "# Step 10: Select features for ML model\n",
    "features = combined_df[[\"close\", \"high\", \"low\", \"ATR\"]].dropna()\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Step 11: Create labels (1 = Buy, 0 = Sell)\n",
    "close_prices = combined_df[\"close\"].values\n",
    "labels = np.where(np.roll(close_prices, -1) > close_prices, 1, 0)\n",
    "\n",
    "# Ensure labels match feature length\n",
    "valid_length = features_scaled.shape[0]  # Get valid feature count\n",
    "labels = labels[:valid_length]  # Trim labels to match features\n",
    "\n",
    "# Step 12: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 13: Train the new model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 14: Save the new model\n",
    "joblib.dump(model, \"new_forex_model_twelvedata.pkl\")\n",
    "\n",
    "print(\"✅ New model trained and saved as 'new_forex_model_twelvedata.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7683a6-ee79-494a-a625-2abbe2a1e809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='new_forex_model_twelvedata.pkl' target='_blank'>new_forex_model_twelvedata.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\hp\\OneDrive\\notebooks\\new_forex_model_twelvedata.pkl"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(\"new_forex_model_twelvedata.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b771a5-8a62-4183-934f-27e5cf2f47c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
